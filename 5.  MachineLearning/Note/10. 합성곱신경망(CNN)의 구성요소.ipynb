{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN(Convolution Neural Network)에서 본 심층신경망(다층 퍼셉트론)의 단점\n",
    "- 입력값으로 고유 이미지 생김새 정보를 알 수 없다.\n",
    "- 2차원 배열 자료를 1차원으로 변경하여 작업이 시작된다.\n",
    "- 심층신경망은 픽셀 하나 하나의 변화에 상당히 민감하다.\n",
    "- 이미지 생김새를 사용할 수 없으므로 한두개의 픽셀이 모델 예측에 영향을 끼친다\n",
    "- 픽셀 한두개의 정보에도 민감하게 반응하기 위해 상당히 많은 변수를 모델 안에 가지고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN의 구성요소 \n",
    "- 밀집층 대신 필터(같은 가중치를 가짐)에 데이터 넣어서 특징점을 뽑아낸다. (심층신경망보다 가중치, 식이 훨씬 줄어듦.) <br><br>    \n",
    "\n",
    "***1차원 합성곱*** \n",
    "* 합성곱 신경망은 노드의 가중치 갯수가 전체 갯수가 아니고 정하여 사용함. (3, 5 : 가중치 3, 5개 )     \n",
    "* 그럼 저 가중치 중에 특징이 있는게 있고, 없는게 있어서 있는 앨 가지고 사용 \n",
    "* 입력층을 아래로 한칸 이동하여 위에서 계산한 **동일한 가중치**와 절편을 사용 \n",
    "* 밀집층보다 가중치의 갯수가 훨씬 적음 \n",
    "* 예를 들어, 10개의 입력이 있으면 출력은 8개 만들어짐     \n",
    "* 가중치 3개, 5개 두는 것을 필터라고 하며, 만약 3개로 지정하면 필터의 커널은 3임.   \n",
    "<br><br>\n",
    "\n",
    "***2차원 합성곱*** <br>\n",
    "* 이미지의 크기는 4x4     \n",
    "* 필터의 커널은 3x3이고, 각 입력층에 곱해지는 Weight와 Bias는 동일하다. \n",
    "* 필터는 여개 쓸  수 있다. 필터의 커널은 정사각형! \n",
    "* 발생하는 출력의 갯수는 2x2개이다. \n",
    "<img src = \"../Data/cnn-07.png\"/>   \n",
    "<br><br>\n",
    "\n",
    "***특성맵*** <br>\n",
    "* 출력된 맵. 특성맵을 활성화 출력이라고도 한다. \n",
    "* 커널과 특성맵 사이에 활성화 함수(Relu)가 들어있기 때문이다!     \n",
    "* 그러나 CNN에서는 특성맵이라고 부른다. \n",
    "* 2차원으로 구성된 입력층은 특성맵도 2차원으로 출력한다. \n",
    "<br><br>\n",
    "\n",
    "***여러개의 필터*** <br>\n",
    "* 필터가 여러개이므로 모든 가중치와 절편이 달라야 한다. \n",
    "* 특성맵의 구성은 (가로x세로x필터갯수)로 3차원이 생성된다. \n",
    "* code) keras.layers.Conv2D(10, kernel_size=(3,3), activation = 'relu') : 10이 필터 갯수 \n",
    "<img src = \"../Data/cnn-08.png\"/>  \n",
    "<br><br>\n",
    "\n",
    "***Padding*** <br>\n",
    "* CNN에서 들어오는 이미지 데이터의 엣지 부분은 기여를 1번밖에 못하고, 센터 부분은 기여를 많이 함. (이미지 처리 시 센터로 모으는 이유)\n",
    "* 패딩을 줘서 가운데로 모이게 하는 효과를 낸다. \n",
    "* 입력값과 동일한 특성맵의 크기를 구하는 방법. \n",
    "* same: 패딩 주는 옵션 \n",
    "* valid: 패딩 주지 않는 옵션 \n",
    "* 들어오는 데이터의 엣지 부분은 기여하는 바가 1번 밖에 없게 됨. \n",
    "* 거의 same padding을 씀 (4x4인 데이터 엣지에 0을 채워서 크게 만든 후 - 패딩을 준 후 - 4x4로 출력하겠다는 의미) \n",
    "* code) keras.layers.Conv2D(10, kernel_size = (3,3), activation = 'relu', padding = 'same')\n",
    "<img src = \"../Data/cnn-09.png\"/> \n",
    "<br><br>\n",
    "\n",
    "***Stride*** <br>\n",
    "* 필터의 이동이 한 칸씩이 아닌 여러 칸으로 이동할 경우 이동하는 크기를 stride라고 한다. \n",
    "* 아주 특수한 경우를 제외하고 stride는 1을 초과하여 사용하지 않는다. (그냥 1이라고 생각하기!)\n",
    "* code) keras.layers.Conv2D(10, kernel_size = (3,3), activation = 'relu', padding = 'same', stride = 1)   \n",
    "<br><br>\n",
    "\n",
    "***Pooling*** <br>\n",
    "* 특성맵의 다음단계를 차원축소 하는 방법 (특징점 뽑아내서 차원축소 해 특성맵 만든걸 다시 특징점 잡아서 차원축소 하는 것!)\n",
    "* 최대풀링 / 평균풀링 2종류가 있다.\n",
    "* 최대풀링 : 특성맵 구역별로 나눠서(겹치지 않는) 최대값으로 차원축소. (보통 최대풀링으로 많이 씀)\n",
    "* 최대풀링은 계산하는 픽셀값이 겹치지 않는다! \n",
    "* 풀링은 가중치가 없으며 풀링의 결과도 특성맵이라고 한다. \n",
    "<br><br>\n",
    "\n",
    "***CNN의 전체 개요*** <br>\n",
    "<img src = \"../Data/cnn-10.png\"/> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dd812dac8ac7f193983fdab392279396e380ee0807f18f6dc7fe840cd918acd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
